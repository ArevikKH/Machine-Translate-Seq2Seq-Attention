{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true,"authorship_tag":"ABX9TyMhNZ6n9ZPXWKWpV5Zw9BmI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Machine Translate | Seq2Seq with Attention"],"metadata":{"id":"Y0Fa1363EnhH"}},{"cell_type":"code","source":["!pip install tqdm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K9b67W2mKLKQ","executionInfo":{"status":"ok","timestamp":1742742580658,"user_tz":-240,"elapsed":2129,"user":{"displayName":"Arevik Khachatryan","userId":"06400131763786536191"}},"outputId":"f215d609-2179-4fe1-9632-a8fbf5c6746e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V_RHjw7VJ2ox","executionInfo":{"status":"ok","timestamp":1742742581964,"user_tz":-240,"elapsed":17,"user":{"displayName":"Arevik Khachatryan","userId":"06400131763786536191"}},"outputId":"a5d5906a-ce5d-4e94-fea2-292e44ea6932"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","import string\n","import re\n","import random\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from sklearn.model_selection import train_test_split\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","source":["Data Preprocessing"],"metadata":{"id":"-XkzRG65KUf_"}},{"cell_type":"code","source":["text_file_path = '/content/rus.txt'\n","with open(text_file_path) as t:\n","    text = t.read()\n","\n","def preprocess_text(text):\n","    text = re.sub(\"'\", '', text)\n","    text = ''.join(char for char in text if char not in string.punctuation)\n","    text = re.sub(\"[0-9]\", '', text)\n","    return text.lower()\n","\n","def return_sentences(text, num_lines=20000):\n","    text_lines = text.split('\\n')\n","    english_texts, russian_texts, english_words, russian_words = [], [], set(), set()\n","\n","    for text_line in tqdm(range(min(len(text_lines), num_lines))):\n","        if not text_lines[text_line].strip():\n","            continue\n","        preprocessed_text_line = preprocess_text(text_lines[text_line])\n","        tab_split_text = preprocessed_text_line.split('\\t')\n","        if len(tab_split_text) < 2:\n","            continue\n","\n","        english_texts.append(tab_split_text[0])\n","        russian_texts.append('<sos> ' + tab_split_text[1] + ' <eos>')\n","\n","        english_words.update(tab_split_text[0].split())\n","        russian_words.update(tab_split_text[1].split())\n","\n","    # Add special tokens\n","    english_words.add('<sos>')\n","    english_words.add('<eos>')\n","    russian_words.add('<sos>')\n","    russian_words.add('<eos>')\n","\n","    return english_texts, russian_texts, sorted(english_words), sorted(russian_words)\n","\n","# Process text\n","english_texts, russian_texts, english_words, russian_words = return_sentences(text)\n","\n","# Create DataFrame\n","text_df = pd.DataFrame({'English': english_texts, 'Russian': russian_texts})\n","text_df['English Length'] = text_df['English'].apply(lambda x: len(x.split()))\n","text_df['Russian Length'] = text_df['Russian'].apply(lambda x: len(x.split()))\n","text_df = text_df.sample(frac=1, random_state=42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pt2mzMYTKGYM","executionInfo":{"status":"ok","timestamp":1742742587099,"user_tz":-240,"elapsed":2583,"user":{"displayName":"Arevik Khachatryan","userId":"06400131763786536191"}},"outputId":"3dfc255f-6b3c-4028-945c-e78087b8a2d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 20000/20000 [00:01<00:00, 14413.00it/s]\n"]}]},{"cell_type":"markdown","source":["Vocabulary & Lookup Tables"],"metadata":{"id":"ZmrDeNDwKXtb"}},{"cell_type":"code","source":["num_encoder_tokens = len(english_words)\n","num_decoder_tokens = len(russian_words) + 1\n","\n","english_lookup = {word: num for num, word in enumerate(english_words)}\n","russian_lookup = {word: num + 1 for num, word in enumerate(russian_words)}\n","russian_lookup['<sos>'] = 0  # Add <sos> with index 0\n","russian_lookup['<eos>'] = num_decoder_tokens - 1\n","russian_token_lookup = {num: word for word, num in russian_lookup.items()}"],"metadata":{"id":"FzgoWGHiKYjZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Dataset & Dataloader"],"metadata":{"id":"BEVMSz-2XZVM"}},{"cell_type":"code","source":["class TranslationDataset(Dataset):\n","    def __init__(self, english_texts, russian_texts, english_lookup, russian_lookup):\n","        self.english_texts = english_texts\n","        self.russian_texts = russian_texts\n","        self.english_lookup = english_lookup\n","        self.russian_lookup = russian_lookup\n","\n","    def __len__(self):\n","        return len(self.english_texts)\n","\n","    def __getitem__(self, idx):\n","        encoder_input = torch.tensor([self.english_lookup[word] for word in self.english_texts[idx].split()], dtype=torch.long)\n","        russian_words = self.russian_texts[idx].split()\n","        decoder_input = torch.tensor([self.russian_lookup[word] for word in russian_words[:-1]], dtype=torch.long)\n","        decoder_target = torch.tensor([self.russian_lookup[word] for word in russian_words[1:]], dtype=torch.long)\n","        return encoder_input, decoder_input, decoder_target\n","\n","def collate_fn(batch):\n","    encoder_inputs, decoder_inputs, decoder_targets = zip(*batch)\n","    return pad_sequence(encoder_inputs, batch_first=True), pad_sequence(decoder_inputs, batch_first=True), pad_sequence(decoder_targets, batch_first=True)\n","\n","\n","X_train, X_valid, y_train, y_valid = train_test_split(text_df['English'], text_df['Russian'], test_size=0.2, random_state=42)\n","\n","# Create dataloaders\n","batch_size = 32\n","train_dataset = TranslationDataset(X_train.tolist(), y_train.tolist(), english_lookup, russian_lookup)\n","valid_dataset = TranslationDataset(X_valid.tolist(), y_valid.tolist(), english_lookup, russian_lookup)\n","\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, num_workers=2)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, num_workers=2)"],"metadata":{"id":"8OIRPHuOXXDq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model Definition"],"metadata":{"id":"jZLzvbjbXeGe"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n","        super(Encoder, self).__init__()\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True, bidirectional=True)\n","        self.dropout = nn.Dropout(dropout)\n","        self.n_layers = n_layers\n","        self.hidden_dim = hidden_dim\n","\n","    def forward(self, src):\n","        embedded = self.dropout(self.embedding(src))\n","        outputs, (hidden, cell) = self.rnn(embedded)\n","\n","        # Combine forward and backward hidden states\n","        hidden = hidden.view(self.n_layers, 2, -1, self.hidden_dim)  # [n_layers, 2, batch_size, hidden_dim]\n","        hidden = hidden[:, 0, :, :] + hidden[:, 1, :, :]  # Sum forward and backward states\n","        hidden = hidden.contiguous()  # [n_layers, batch_size, hidden_dim]\n","\n","        # Combine forward and backward cell states\n","        cell = cell.view(self.n_layers, 2, -1, self.hidden_dim)  # [n_layers, 2, batch_size, hidden_dim]\n","        cell = cell[:, 0, :, :] + cell[:, 1, :, :]  # Sum forward and backward states\n","        cell = cell.contiguous()  # [n_layers, batch_size, hidden_dim]\n","\n","        return outputs, hidden, cell\n","\n","\n","class Attention(nn.Module):\n","    def __init__(self, hidden_dim):\n","        super(Attention, self).__init__()\n","        self.attn = nn.Linear(hidden_dim * 3, hidden_dim)  # Adjusted for bidirectional encoder\n","        self.v = nn.Parameter(torch.rand(hidden_dim))\n","\n","    def forward(self, hidden, encoder_outputs, mask=None):\n","        # hidden: [batch_size, hidden_dim]\n","        # encoder_outputs: [batch_size, seq_len, hidden_dim * 2]\n","\n","        # Repeat hidden state to match sequence length\n","        seq_len = encoder_outputs.shape[1]\n","        hidden = hidden.unsqueeze(1).repeat(1, seq_len, 1)  # [batch_size, seq_len, hidden_dim]\n","\n","        combined = torch.cat((hidden, encoder_outputs), dim=2)  # [batch_size, seq_len, hidden_dim * 3]\n","\n","        # Compute attention energy\n","        energy = torch.tanh(self.attn(combined))  # [batch_size, seq_len, hidden_dim]\n","        attention = torch.sum(self.v * energy, dim=2)  # [batch_size, seq_len]\n","\n","        if mask is not None:\n","            attention = attention.masked_fill(mask == 0, -1e10)  # Set masked positions to a very low value\n","\n","        # Normalize attention weights\n","        return torch.softmax(attention, dim=1).unsqueeze(1)  # [batch_size, 1, seq_len]\n","\n","\n","class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout, attention):\n","        super(Decoder, self).__init__()\n","\n","        self.output_dim = output_dim\n","        self.attention = attention\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim + hidden_dim * 2, hidden_dim, num_layers=n_layers, dropout=dropout, batch_first=True)\n","        self.fc_out = nn.Linear(hidden_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input, hidden, cell, encoder_outputs):\n","        \"\"\"\n","        input: [batch_size]\n","        hidden: [n_layers, batch_size, hidden_dim]\n","        cell: [n_layers, batch_size, hidden_dim]\n","        encoder_outputs: [batch_size, src_len, hidden_dim * 2]\n","        \"\"\"\n","        input = input.unsqueeze(1)  # Reshape to [batch_size, 1]\n","        embedded = self.dropout(self.embedding(input))  # [batch_size, 1, emb_dim]\n","\n","        attn_weights = self.attention(hidden[-1], encoder_outputs)  # [batch_size, 1, src_len]\n","        context = torch.bmm(attn_weights, encoder_outputs)  # [batch_size, 1, hidden_dim * 2]\n","\n","        # Concatenate context and embedded input\n","        rnn_input = torch.cat((embedded, context), dim=2)  # [batch_size, 1, emb_dim + hidden_dim * 2]\n","        # Pass through the LSTM\n","        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n","        # Output shape after LSTM: [batch_size, seq_len, hidden_dim]\n","        output = output.squeeze(1)  # Remove the seq_len dimension: [batch_size, hidden_dim]\n","        # Pass through the fully connected layer\n","        prediction = self.fc_out(output)  # [batch_size, output_dim]\n","\n","        return prediction, hidden, cell\n","\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super(Seq2Seq, self).__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n","        batch_size = src.shape[0]\n","        trg_len = trg.shape[1]\n","        trg_vocab_size = self.decoder.fc_out.out_features\n","\n","        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n","        encoder_outputs, hidden, cell = self.encoder(src)\n","\n","        input = trg[:, 0]\n","        for t in range(1, trg_len):\n","            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n","            outputs[:, t] = output\n","            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n","            input = trg[:, t] if teacher_force else output.argmax(1)\n","\n","        return outputs"],"metadata":{"id":"90jhNV4Y6DlV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training Setup"],"metadata":{"id":"lLaopT9EXisc"}},{"cell_type":"code","source":["input_dim = num_encoder_tokens  # Vocabulary size\n","embedding_dim, hidden_dim = 256, 512\n","n_layers = 2\n","dropout = 0.5\n","attention = Attention(hidden_dim)\n","output_dim = num_decoder_tokens\n","encoder = Encoder(input_dim, embedding_dim, hidden_dim, n_layers, dropout).to(device)\n","decoder = Decoder(output_dim, embedding_dim, hidden_dim, n_layers, dropout, attention).to(device)\n","model = Seq2Seq(encoder, decoder, device).to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss(ignore_index=0)\n","\n","def train(model, dataloader, optimizer, criterion, clip=1.0):\n","    model.train()\n","    epoch_loss = 0\n","\n","    for src, trg_input, trg_output in tqdm(dataloader):\n","        src, trg_input, trg_output = src.to(device), trg_input.to(device), trg_output.to(device)\n","        optimizer.zero_grad()\n","        output = model(src, trg_input)\n","\n","        output_dim = output.shape[-1]\n","        loss = criterion(output.view(-1, output_dim), trg_output.view(-1))\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","    return epoch_loss / len(dataloader)\n","\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    train_loss = train(model, train_dataloader, optimizer, criterion)\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8dzKT4psXgYH","executionInfo":{"status":"ok","timestamp":1742743541600,"user_tz":-240,"elapsed":151477,"user":{"displayName":"Arevik Khachatryan","userId":"06400131763786536191"}},"outputId":"b1a629b2-f687-4c19-ea92-537645bdbddc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:15<00:00, 32.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Loss: 6.0795\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:15<00:00, 32.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Loss: 5.4514\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:15<00:00, 32.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Loss: 4.9839\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:14<00:00, 33.81it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Loss: 4.5859\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:14<00:00, 33.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Loss: 4.2667\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:15<00:00, 32.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Loss: 4.0027\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:15<00:00, 33.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Loss: 3.7884\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:14<00:00, 33.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, Loss: 3.6227\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:14<00:00, 33.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, Loss: 3.4879\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 500/500 [00:15<00:00, 33.30it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Loss: 3.3880\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["def translate_sentence(sentence, model, english_lookup, russian_token_lookup, max_length=50):\n","    sentence = preprocess_text(sentence)\n","    input_tokens = sentence.split()\n","\n","    input_tensor = torch.tensor([english_lookup.get(word, 0) for word in input_tokens], dtype=torch.long).to(device).unsqueeze(0)\n","\n","    decoder_input = torch.tensor([russian_lookup['<sos>']], dtype=torch.long).to(device)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        encoder_outputs, hidden, cell = model.encoder(input_tensor)\n","        output_tokens = []\n","\n","        for _ in range(max_length):\n","            output, hidden, cell = model.decoder(decoder_input, hidden, cell, encoder_outputs)\n","            top1 = output.argmax(1).item()\n","            output_tokens.append(top1)\n","\n","            if top1 == russian_lookup['<eos>']:\n","                break\n","\n","            decoder_input = torch.tensor([top1], dtype=torch.long).to(device)\n","\n","    translated_words = [russian_token_lookup[token] for token in output_tokens]\n","    return ' '.join(translated_words)"],"metadata":{"id":"OBsrGRqUK1oe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#english_sentence = \"hello how are you\"\n","# Input (English): hello how are you\n","# Translated (Russian): как дела —\n","english_sentence = \"I am working\"\n","\n","translated_sentence = translate_sentence(english_sentence, model, english_lookup, russian_token_lookup)\n","\n","print(f\"Input (English): {english_sentence}\")\n","print(f\"Translated (Russian): {translated_sentence}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TmKn6XI4HS-x","executionInfo":{"status":"ok","timestamp":1742743588310,"user_tz":-240,"elapsed":11,"user":{"displayName":"Arevik Khachatryan","userId":"06400131763786536191"}},"outputId":"0f62a8db-2e6b-4de9-9cfb-5a3271c3fab9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input (English): I am working\n","Translated (Russian): работаю —\n"]}]}]}
